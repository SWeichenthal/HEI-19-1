{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/scott/Dropbox/HEI_19_1_Deep_Learning_Models'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set working directory. make sure metadata and images are in folders in the working directory\n",
    "os.chdir('set_your_working_directory/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 24 16:08:13 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN Xp     Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 23%   33C    P8    10W / 250W |    202MiB / 12194MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN Xp     Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 23%   34C    P8     9W / 250W |     11MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA TITAN Xp     Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 23%   33C    P8     9W / 250W |     11MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA TITAN Xp     Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 23%   31C    P8     9W / 250W |     11MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1468      G   /usr/lib/xorg/Xorg                 18MiB |\n",
      "|    0   N/A  N/A      2592      G   /usr/bin/gnome-shell               63MiB |\n",
      "|    0   N/A  N/A      3982      G   /usr/lib/xorg/Xorg                 66MiB |\n",
      "|    0   N/A  N/A      4113      G   /usr/bin/gnome-shell               22MiB |\n",
      "|    0   N/A  N/A      4137      G   ...mviewer/tv_bin/TeamViewer       26MiB |\n",
      "|    1   N/A  N/A      1468      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      3982      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A      1468      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A      3982      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A      1468      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A      3982      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# check the GPUs, make sure they are not being used\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Root Mean Squared Error Loss Function\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.backend.sqrt(K.backend.mean(K.backend.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "### loop does all 3 pollutants #####\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which city: to or mtl? mtl\n",
      "Set minimum number of monitoring days per road segment: 6\n",
      "Set initial learning rate: 0.0001\n",
      "Max number of epochs? 2\n"
     ]
    }
   ],
   "source": [
    "# specify the city\n",
    "city = input(\"Which city: to or mtl? \")\n",
    "\n",
    "# specify the minimum number of monitoring days per road segment. \n",
    "min_number_of_monitoring_days = int(input(\"Set minimum number of monitoring days per road segment: \"))\n",
    "initial_learning_rate = float(input(\"Set initial learning rate: \")) # good to start with 0.0001\n",
    "initial_learning_rate_str = \"{0:.0e}\".format(initial_learning_rate) + 'lr'\n",
    "\n",
    "# set the max number of epochs to train. Good to start with at least 20. Then if it's working well, go to 100 and train overnight\n",
    "num_epochs = input(\"Max number of epochs? \")\n",
    "num_epochs = int(num_epochs)\n",
    "if num_epochs > 50:\n",
    "    print('!!! Are you sure you want to train up to ' + str(num_epochs) + 'epochs?')\n",
    "\n",
    "# some details relevant to the metadata, this will help with pointing to folders, to columns in the metadata, and with naming files that will be saved (e.g. model training log)\n",
    "image_type = \"satellite\"\n",
    "zoom_1 = 'images_18'\n",
    "zoom_2 = 'images_19'\n",
    "image_file_name = 'sat_file'\n",
    "\n",
    "# continuous outcome\n",
    "tv_class_mode = 'raw'\n",
    "test_class_mode = None \n",
    "\n",
    "# loop will train models for each pollutant. 'ufp', 'size' and 'bc' are the names of separate columns in the metadata that indicate the ufp number concentration, mean ufp size, and bc mass concentrations\n",
    "pollutant = ['ufp', 'size', 'bc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9316 validated image filenames.\n",
      "Found 2500 validated image filenames.\n",
      "Found 2304 validated image filenames.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/2\n",
      "INFO:tensorflow:batch_all_reduce: 156 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 156 all-reduces with algorithm = nccl, num_packs = 1\n",
      "73/73 [==============================] - 861s 7s/step - loss: 6.2556 - rmse: 6.2539 - mae: 6.1488 - val_loss: 9.6634 - val_rmse: 9.6475 - val_mae: 9.5763\n",
      "Epoch 2/2\n",
      "73/73 [==============================] - 51s 696ms/step - loss: 0.7076 - rmse: 0.7081 - mae: 0.5363 - val_loss: 3.7488 - val_rmse: 3.7408 - val_mae: 3.6880\n",
      "Found 9316 validated image filenames.\n",
      "Found 2500 validated image filenames.\n",
      "Found 2304 validated image filenames.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n",
      "Epoch 1/2\n",
      "INFO:tensorflow:batch_all_reduce: 156 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 156 all-reduces with algorithm = nccl, num_packs = 1\n",
      "73/73 [==============================] - 152s 786ms/step - loss: 27.9475 - rmse: 27.9449 - mae: 26.8990 - val_loss: 9.1033 - val_rmse: 9.0327 - val_mae: 7.4537\n",
      "Epoch 2/2\n",
      "73/73 [==============================] - 50s 676ms/step - loss: 21.5853 - rmse: 21.5846 - mae: 20.4232 - val_loss: 10.0928 - val_rmse: 10.0081 - val_mae: 8.4591\n",
      "Found 9374 validated image filenames.\n",
      "Found 2532 validated image filenames.\n",
      "Found 2330 validated image filenames.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n",
      "Epoch 1/2\n",
      "INFO:tensorflow:batch_all_reduce: 156 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 156 all-reduces with algorithm = nccl, num_packs = 1\n",
      "74/74 [==============================] - 480s 5s/step - loss: 3.9705 - rmse: 3.9563 - mae: 3.8371 - val_loss: 4.7930 - val_rmse: 4.7959 - val_mae: 4.6603\n",
      "Epoch 2/2\n",
      "74/74 [==============================] - 49s 663ms/step - loss: 0.6182 - rmse: 0.6507 - mae: 0.4761 - val_loss: 2.1304 - val_rmse: 2.1302 - val_mae: 2.0264\n"
     ]
    }
   ],
   "source": [
    "# loop will train models for each of the pollutants\n",
    "for i in pollutant:\n",
    "    \n",
    "    # the metadata has a column for each pollutant measure (i.e., ufp_median, size_median, bc_median)\n",
    "    if i == 'size':\n",
    "        exposure = i + '_' + 'median'\n",
    "    else:\n",
    "        exposure = 'log_' + i + '_' + 'median' # ufp and bc concentrations have been log-transformed in the metadata. the ufp and bc concentration columns in the metadata are called \"log_ufp_median\" and \"log_ufp_median\" respectively\n",
    "    \n",
    "    # the metadata has a column that denotes the number of monitoring days per road segment for UFP/Size and BC\n",
    "    if i == \"bc\":\n",
    "        p_filter = 'days' + '_' + i\n",
    "    if i == \"ufp\":\n",
    "        p_filter = 'days' + '_' + i\n",
    "    if i == \"size\":\n",
    "        p_filter = 'days' + '_ufp'\n",
    "    \n",
    "    # read in the metadata. There were separate monitoring campaigns in Montreal and Toronto. This models each city separately\n",
    "    # you may have a different fileplan, so you'll have to update the filepath and filename\n",
    "    if city == \"to\":\n",
    "        dat = pd.read_csv(filepath_or_buffer = \"data_files/images/to_images/model_development_images/t100_new_image_metadata.csv\")\n",
    "\n",
    "    # you may have a different fileplan, so you'll have to update the filepath and filename\n",
    "    if city == \"mtl\":\n",
    "        dat = pd.read_csv(filepath_or_buffer = \"data_files/images/mtl_images/model_development_images/m100_new_image_metadata.csv\")\n",
    "\n",
    "    # remove excess columns from metadata\n",
    "    if i == 'size':\n",
    "        dat = dat[[image_file_name, 'set_ghp6', p_filter, exposure, 'temp', 'hum', 'ws']]\n",
    "    else:\n",
    "        dat = dat[[image_file_name, 'set_ghp6', p_filter, exposure, i + '_' + 'median', 'temp', 'hum', 'ws']]\n",
    "\n",
    "    # subset to observations where exposure is nonmissing\n",
    "    dat = dat[dat[exposure].notnull()].reset_index(drop=True)\n",
    "\n",
    "    dat[[exposure]] = dat[[exposure]].astype(\"float32\")\n",
    "    \n",
    "    # there are satellite images at two zoom levels for each road segment. create a row in the metadata for each image\n",
    "    s1, s2 = dat.copy(), dat.copy()\n",
    "\n",
    "    s1[image_file_name] = city+'_' +zoom_1+'/' + s1[image_file_name]\n",
    "    s2[image_file_name] = city+'_' +zoom_2+'/' + s2[image_file_name]\n",
    "\n",
    "    dat = pd.concat([s1, s2])\n",
    "       \n",
    "    # remove observations below the cut off (i.e. any road segments that were monitored on fewer days will be removed from the analysis, pollution measures from these \"low number of monitoring days\" road segments are too temporally unstable to be useful)\n",
    "    dat = dat[dat[p_filter] >= min_number_of_monitoring_days]\n",
    "\n",
    "    # prepare the generators, these point to where the images are, specify preprocessing, and specify batch size\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=K.applications.xception.preprocess_input,\n",
    "                                                         horizontal_flip=True, \n",
    "                                                         vertical_flip = True)\n",
    "\n",
    "\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=dat.loc[dat['set_ghp6']=='train', [exposure, image_file_name]].reset_index(drop=True),\n",
    "                                                    directory='data_files/images/'+city+'_images/model_development_images/'+image_type+'_view_100m/',      # you may have a different fileplan, so you'll have to update the filepath to the images you are using the train the models\n",
    "                                                    x_col= image_file_name,\n",
    "                                                    y_col=exposure,\n",
    "                                                    #has_ext=True, #depreciated, not needed because we already have the extension on our filenames\n",
    "                                                    class_mode=tv_class_mode,\n",
    "                                                    target_size=(256, 256),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=32*4,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=dat.loc[dat['set_ghp6']=='validate', [exposure, image_file_name]].reset_index(drop=True),\n",
    "                                                         directory='data_files/images/'+city+'_images/model_development_images/'+image_type+'_view_100m/',   # you may have a different fileplan, so you'll have to update the filepath to the images you are using the train the models\n",
    "                                                         x_col= image_file_name,\n",
    "                                                         y_col=exposure,\n",
    "                                                         #has_ext=True, #depreciated, not needed because we already have the extension on our filenames\n",
    "                                                         class_mode=tv_class_mode,\n",
    "                                                         target_size=(256, 256),\n",
    "                                                         color_mode='rgb',\n",
    "                                                         batch_size=32*4,\n",
    "                                                         shuffle=False)\n",
    "\n",
    "    test_generator = generator.flow_from_dataframe(dataframe=dat.loc[dat['set_ghp6']=='test', [exposure, image_file_name]].reset_index(drop=True),\n",
    "                                                   directory='data_files/images/'+city+'_images/model_development_images/'+image_type+'_view_100m/',   # you may have a different fileplan, so you'll have to update the filepath to the images you are using the train the models\n",
    "                                                   x_col= image_file_name,\n",
    "                                                   #has_ext=True, #depreciated, not needed because we already have the extension on our filenames\n",
    "                                                   class_mode= test_class_mode,\n",
    "                                                   target_size=(256, 256),\n",
    "                                                   color_mode='rgb',\n",
    "                                                   batch_size=32*4,\n",
    "                                                   shuffle=False)\n",
    "\n",
    "    # set callbacks, you may have a different fileplan, so you'll have to update the filepath and filename\n",
    "    early_stopping = K.callbacks.EarlyStopping(monitor='val_rmse', patience=15)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_rmse', factor=0.1, patience=5, mode='min', verbose=1)\n",
    "    csv_logger = K.callbacks.CSVLogger('model_development/model_logs/'+city+'_'+image_type+'/'+city+', '+exposure+', '+p_filter+' min '+str(min_number_of_monitoring_days)+' days, '+image_type+', ' + initial_learning_rate_str + '.csv')\n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('model_development/models/'+city+'_'+image_type+'/'+city+', '+exposure+', '+p_filter+' min '+str(min_number_of_monitoring_days)+' days, '+image_type+', ' + initial_learning_rate_str + '.hdf5', monitor='val_rmse', mode='min', save_weights_only=False, save_best_only=True)\n",
    "\n",
    "    # define continous CNN model\n",
    "    def get_compiled_model():\n",
    "        # define model\n",
    "        model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "        conv_base = K.applications.Xception(include_top=False, weights='imagenet', input_tensor=model_input)\n",
    "        model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "        model_output = K.layers.Dense(units=1, activation='linear')(model_output)\n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        model.compile(\n",
    "            optimizer=K.optimizers.Nadam(lr= initial_learning_rate),\n",
    "            loss = rmse,   # or MeanSquaredError(), or K.losses.MeanAbsoluteError(reduction=\"auto\", name=\"mean_absolute_error\")\n",
    "            metrics = [rmse,'mae']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    # Create a MirroredStrategy\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "    # Open a strategy scope and compile the model\n",
    "    with strategy.scope():\n",
    "        model = get_compiled_model()\n",
    "\n",
    "    # Train the model on all available devices\n",
    "    for layer in model.layers: layer.trainable = True\n",
    "\n",
    "    # train the model\n",
    "    model.fit(train_generator, \n",
    "              validation_data=validate_generator,\n",
    "              epochs=num_epochs, \n",
    "              steps_per_epoch=int(np.ceil(train_generator.samples/train_generator.batch_size)),\n",
    "              validation_steps=int(np.ceil(validate_generator.samples/validate_generator.batch_size)),\n",
    "              callbacks=[early_stopping, reduce_lr_on_plateau, csv_logger, model_checkpoint])\n",
    "\n",
    "    # load model generate predictions in the test set, you may have a different fileplan, so you'll have to update the filepath and filename\n",
    "    model = K.models.load_model('model_development/models/'+city+'_'+image_type+'/'+city+', '+exposure+', '+p_filter+' min '+str(min_number_of_monitoring_days)+' days, '+image_type+', ' + initial_learning_rate_str + '.hdf5', custom_objects={'rmse': rmse})\n",
    "\n",
    "    results = dat.loc[dat['set_ghp6']=='test', [image_file_name, 'set_ghp6', 'temp', 'hum', 'ws', i + '_' + 'median', exposure]].copy().rename(columns={'file': 'File', 'set_ghp6': 'Set', 'temp': 'Temp', 'hum': 'Hum', 'ws': 'Wind_Speed', i + '_' + 'median': i + '_' + 'median', exposure: exposure}).reset_index(drop=True)\n",
    "\n",
    "    results[exposure+'_pred'] = model.predict(x=test_generator, steps=int(np.ceil(test_generator.samples/test_generator.batch_size)))\n",
    "    \n",
    "    # save and show the results, you may have a different fileplan, so you'll have to update the filepath and filename\n",
    "    results.to_csv(path_or_buf='model_development/model_predictions/'+city+'_'+image_type+'/'+city+', '+exposure+', '+p_filter+' '+str(min_number_of_monitoring_days)+'o, '+image_type+', ' + initial_learning_rate_str + '.csv', index=False)\n",
    "    results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "######## Generate predictions ###############\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which city: to or mtl? mtl\n",
      "Set minimum number of monitoring days per road segment: 6\n",
      "Model was trained using which initial learning rate? 0.0001\n",
      "Use which set of images? prediction or development? development\n"
     ]
    }
   ],
   "source": [
    "# specify the city, exposure and the images for training. Note 'size' is ufp mean size\n",
    "city = input(\"Which city: to or mtl? \")\n",
    "min_number_of_monitoring_days = int(input(\"Set minimum number of monitoring days per road segment: \"))\n",
    "initial_learning_rate = float(input(\"Model was trained using which initial learning rate? \")) # good to start with 0.0001\n",
    "initial_learning_rate_str = \"{0:.0e}\".format(initial_learning_rate) + 'lr'\n",
    "\n",
    "# this will help point to folders and metadata columns \n",
    "image_type = 'satellite'\n",
    "zoom_angle_1 = 'images_18'\n",
    "zoom_angle_2 = 'images_19'\n",
    "image_file_name = 'sat_file'\n",
    "\n",
    "# continuous outcome\n",
    "tv_class_mode = 'raw'\n",
    "test_class_mode = None \n",
    "\n",
    "# can generate predictions on all the model development images (i.e. for the monitoring sites) or for the prediction surface (i.e. the fishnet, all the 100 m x 100 m cells in the study area)\n",
    "dev_or_pred_images = input(\"Use which set of images? prediction or development? \")   \n",
    "\n",
    "# there are model development images (i.e. image paired with monitoring data) and model prediction images (i.e. the prediction surface aka the fishnet)\n",
    "    # the two different groups of images were maintained in two different databases. The images themseleves have the same specifications (e.g., zoom level and resolution), but they were used for different purposes\n",
    "    # depending on the choice made above, the code will generate predictions using the model development images or the prediction surface images\n",
    "if dev_or_pred_images == 'prediction':\n",
    "    pred_image_gis_file = 'fishnet'\n",
    "    end_image_folder_name = 'fishnet' \n",
    "else:\n",
    "    if dev_or_pred_images == 'development':\n",
    "        pred_image_gis_file = '100m_new_dev' \n",
    "        end_image_folder_name = '100m'      \n",
    "\n",
    "# generate predictions using the different models for each of the pollutants. \n",
    "pollutant = ['ufp', 'size', 'bc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30930 validated image filenames.\n",
      "Found 30930 validated image filenames.\n",
      "Found 30930 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "for i in pollutant:\n",
    "\n",
    "    # exposure and p_filter are in the model names\n",
    "    if i == 'size':\n",
    "        exposure = i + '_' + 'median'\n",
    "    else:\n",
    "        exposure = 'log_' + i + '_' + 'median'\n",
    "    \n",
    "    if i == \"bc\":\n",
    "        p_filter = 'days' + '_' + i\n",
    "    if i == \"ufp\":\n",
    "        p_filter = 'days' + '_' + i\n",
    "    if i == \"size\":\n",
    "        p_filter = 'days' + '_ufp'\n",
    "    \n",
    "    # load in the metadata. there is metadata for each city, and there is the model development metadata (useful for model evaluation) and prediction surface metadata (which does not have observed pollution levels, but does have the lat and long of the image which is used to place the prediction in space)\n",
    "    # you may have a different fileplan, so you'll have to update the filepath and filename\n",
    "    if city == \"to\":\n",
    "        if dev_or_pred_images == 'prediction':\n",
    "            dat = pd.read_csv(filepath_or_buffer = \"data_files/images/to_images/model_prediction_images/t_fishnet_image_metadata.csv\")\n",
    "        else:\n",
    "            dat = pd.read_csv(filepath_or_buffer = \"data_files/images/to_images/model_development_images/t100_new_image_metadata.csv\")                \n",
    "            dat.rename(columns = {'point_lon':'lon', 'point_lat':'lat'}, inplace = True)\n",
    "\n",
    "    # you may have a different fileplan, so you'll have to update the filepath and filename\n",
    "    if city == \"mtl\":\n",
    "        if dev_or_pred_images == 'prediction':\n",
    "            dat = pd.read_csv(filepath_or_buffer = \"data_files/images/mtl_images/model_prediction_images/m_fishnet_image_metadata.csv\")\n",
    "        else:\n",
    "            dat = pd.read_csv(filepath_or_buffer = \"data_files/images/mtl_images/model_development_images/m100_new_image_metadata.csv\")   \n",
    "            dat.rename(columns = {'point_lon':'lon', 'point_lat':'lat'}, inplace = True)                \n",
    "\n",
    "    # remove excess columns\n",
    "    dat = dat[[image_file_name, 'site_id', 'lon', 'lat']]\n",
    "    \n",
    "    # will generate predictions on images of both zoom levels\n",
    "    s1, s2 = dat.copy(), dat.copy()\n",
    "\n",
    "    s1[image_file_name] = 'model_'+dev_or_pred_images+'_images/'+image_type+'_view_'+end_image_folder_name+'/'+city+'_' +zoom_angle_1+'/' + s1[image_file_name]\n",
    "    s2[image_file_name] = 'model_'+dev_or_pred_images+'_images/'+image_type+'_view_'+end_image_folder_name+'/'+city+'_' +zoom_angle_2+'/' + s2[image_file_name]\n",
    "\n",
    "    dat = pd.concat([s1, s2])\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=K.applications.xception.preprocess_input,\n",
    "                                                         horizontal_flip=False, \n",
    "                                                         vertical_flip = False) \n",
    "\n",
    "    test_generator = generator.flow_from_dataframe(dataframe=dat,\n",
    "                                                   directory='data_files/images/'+city+'_images/',    # you may have a different fileplan, so you'll have to update the filepath to the images you are using the train the models\n",
    "                                                   x_col= image_file_name,\n",
    "                                                   class_mode= test_class_mode,\n",
    "                                                   target_size=(256, 256),\n",
    "                                                   color_mode='rgb',\n",
    "                                                   batch_size=32*4,\n",
    "                                                   shuffle=False)\n",
    "\n",
    "    # load model, you may have a different fileplan, so you'll have to update the filepath and filename\n",
    "    model = K.models.load_model('model_development/models/'+city+'_'+image_type+'/'+city+', '+exposure+', '+p_filter+' min '+str(min_number_of_monitoring_days)+' days, '+image_type+', ' + initial_learning_rate_str + '.hdf5', custom_objects={'rmse': rmse})\n",
    "\n",
    "    # create a results dataframe based on the metadata\n",
    "    results = dat\n",
    "\n",
    "    # generate predictions and include in results dataframe\n",
    "    results[exposure+'_prediction'] = model.predict(x=test_generator, steps=int(np.ceil(test_generator.samples/test_generator.batch_size)))\n",
    "\n",
    "    # save results as csv, you may have a different fileplan, so you'll have to update the filepath and filename\n",
    "    results.to_csv(path_or_buf='model_development/model_predictions/'+city+'_'+pred_image_gis_file+'_'+image_type+'/'+city+', '+exposure+', '+p_filter+' min '+str(min_number_of_monitoring_days)+' days, '+image_type+', ' + initial_learning_rate_str + '.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
